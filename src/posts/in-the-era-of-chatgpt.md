---
layout: post
title: "In the Era of ChatGPT and friends"
author: [masimplo]
tags: []
image: ../images/headers/possessed-photography-jIBMSMs4_kA-unsplash.jpg
date: "2023-01-13"
draft: false
---

AI technology is advancing rapidly and changing many aspects of our lives, including the way we communicate and write. One of the most striking examples of this is the ability of computer models such as GPT-3 to produce text that mimics human writing so effectively, that it can be difficult to distinguish it from work produced by actual authors and thinkers.

GPT-3, an advanced AI model, has the capability to generate text that is extremely realistic and closely resembles human writing, making it difficult to distinguish between the two. It is also so well-versed and knowledgeable that it can present arguments and information in a convincing manner, making it challenging to distinguish fact from fiction, adding another layer of complexity to the process of verifying information. And this is just the beginning, as advancements in AI technology continue to push the boundaries of what is possible.

Yuval Noah Harari, the historian and philosopher, has been talking about this for years. In his books Sapiens and Homo Deus, he writes about how technology is blurring the line between human and machine. And he's not just talking about the future, he's talking about now. We're already living in a world where it's becoming increasingly difficult to tell the difference between a real person and a computer-generated one.

You might be wondering what the significance of this development is. If a computer can create literature of equal quality to that produced by a human, does it really matter if a human didn't physically write it? However, this raises important questions about authenticity. If we are unable to distinguish between human and machine-generated content, what does that say about our understanding of ourselves and our own authenticity?

The implications of this development extend beyond just philosophical considerations. The blurring of the line between human and machine-generated content has far-reaching effects on various fields such as journalism and creative writing. In journalism, credibility and accuracy of information is vital for maintaining the trust of the audience and presenting them with reliable information. However, if it becomes increasingly difficult to distinguish between human and machine-generated text, the question of the authenticity and credibility of the information presented becomes more complex.

Similarly, the advancement of AI in creative writing also raise questions about the definition of inspiration and originality. With machine-generated text becoming increasingly sophisticated, it becomes harder to discern between works that were truly inspired by human emotions, thoughts and experiences and those generated by algorithms. This raises ethical questions about authorship and credit in creative field that are also worth to be discussed.

It reminds me of pre-war steel in some sense. Low-background steel is much more valuable than modern steel as it has a much lower radiation signature, making it more valuable as it can be used in some niche application like particle detectors, Geiger counters etc. I think we are at a similar point in history for content, as anything below this point might be "polluted" by new AI advent.

It reminds me of pre-war steel in some sense. The concept of low-background steel brings to mind a comparison to pre-war steel, in terms of its purity and value. Unlike modern steel, low-background steel has a much lower radiation signature, making it highly sought-after for specialized applications such as particle detectors and Geiger counters. Similarly, in the context of content, there is a growing sentiment that pre-AI era content holds more value as it is considered to be authentic and pure, while post-AI content may be viewed as "polluted" or less credible due to the advancements in AI's ability to generate text. This analogy of "polluted" content, just like low-background steel being polluted by radiation, highlights the importance of authenticity in the era of AI.

The fact is, AI is changing the world, and it's important that we start thinking about the implications. Harari calls it the "age of disinformation," where it becomes harder and harder to separate fact from fiction. It's up to us to decide how we want to navigate this new landscape.

So next time you read a piece of text, think about whether or not it was written by a machine. And if you can't tell, does it really matter?
